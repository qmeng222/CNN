{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnpdZLCVYV0tP8QcjUbRCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qmeng222/CNN/blob/main/RNN/GRU_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hWjdG_WX8TUK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. LSTM:"
      ],
      "metadata": {
        "id": "fc_yo4iX8gXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "input_size  =  9 # number of data channels\n",
        "hidden_size = 16 # number of units in the hidden state\n",
        "num_layers  =  2 # number of vertical stacks of hidden layers\n",
        "\n",
        "# create an LSTM instance\n",
        "lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
        "lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rias7trc8ijj",
        "outputId": "d2a1514a-ac3a-4740-9567-91182d814978"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(9, 16, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set data parameters\n",
        "seqlength = 5\n",
        "batchsize = 2\n",
        "\n",
        "# create some random data\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "\n",
        "# create initial hidden states (typically initialized as zeros)\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size) # hidden state\n",
        "C = torch.zeros(num_layers,batchsize,hidden_size) # cell state\n",
        "\n",
        "# (hidden,cell) tuple\n",
        "hiddeninputs = (H,C)\n",
        "\n",
        "# pass through the model & check sizes\n",
        "y,h = lstm(X,hiddeninputs) # 3 inputs: current input, previous hidden state, and previous cell state\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h[0].shape)}') # h is a tuple of (hidden,cell)\n",
        "print(f'  Cell shape: {list(h[1].shape)}')\n",
        "print(f'Output shape: {list(y.shape)}') # final output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP5V1dGbgPYt",
        "outputId": "52d87d58-09ce-4cfb-e638-195eeec74821"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [2, 2, 16]\n",
            "  Cell shape: [2, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the learned parameters and their sizes\n",
        "for p in lstm.named_parameters():\n",
        "  print(p)\n",
        "  if 'weight' in p[0]:\n",
        "    print(f'{p[0]} has size {list(p[1].shape)}')\n",
        "  print(\"-------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOECkxpnj83J",
        "outputId": "6ca7bafb-bb6c-41e4-c690-df99d29d1cb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight_ih_l0', Parameter containing:\n",
            "tensor([[ 0.1542, -0.0360,  0.1344, -0.2426,  0.0506, -0.1397,  0.1742,  0.1688,\n",
            "          0.0201],\n",
            "        [ 0.2138, -0.0117,  0.1152,  0.1323, -0.1030, -0.2132,  0.0399, -0.0536,\n",
            "          0.0445],\n",
            "        [ 0.0215,  0.0241,  0.1133, -0.1527,  0.2128,  0.1725,  0.2045, -0.0369,\n",
            "          0.1946],\n",
            "        [ 0.0055, -0.0824, -0.1713, -0.2223,  0.0827,  0.2189, -0.1868,  0.2150,\n",
            "         -0.2453],\n",
            "        [-0.2213, -0.0312,  0.1743, -0.0336,  0.0115,  0.2174,  0.2426, -0.0560,\n",
            "         -0.2279],\n",
            "        [-0.0202, -0.1292, -0.1979, -0.0239,  0.2074, -0.1665, -0.0763,  0.0373,\n",
            "          0.0610],\n",
            "        [ 0.0877, -0.0642,  0.1015,  0.1242, -0.1975, -0.0943, -0.2011,  0.1507,\n",
            "          0.2238],\n",
            "        [ 0.0851, -0.1968,  0.0987, -0.1499, -0.2237, -0.1059,  0.0944, -0.2003,\n",
            "         -0.0227],\n",
            "        [ 0.2017,  0.2082,  0.1940, -0.2413,  0.0638, -0.0010, -0.1681,  0.0767,\n",
            "          0.0797],\n",
            "        [ 0.2176, -0.1465, -0.0302, -0.1297, -0.1041, -0.1107, -0.0927,  0.0231,\n",
            "         -0.0271],\n",
            "        [-0.1323,  0.0602, -0.1190,  0.1625, -0.1399,  0.0976, -0.1253, -0.0941,\n",
            "         -0.2144],\n",
            "        [-0.2161, -0.0680, -0.2323, -0.0355,  0.1616,  0.2486, -0.1858,  0.2174,\n",
            "         -0.2496],\n",
            "        [-0.2053,  0.0782, -0.2388,  0.2141,  0.0263, -0.0622,  0.1248, -0.1958,\n",
            "          0.0337],\n",
            "        [-0.1538, -0.0724, -0.1241,  0.1106, -0.1578, -0.0547,  0.0577, -0.1622,\n",
            "         -0.1495],\n",
            "        [-0.1877,  0.2167,  0.0624, -0.0393, -0.2437, -0.0597,  0.0473,  0.0410,\n",
            "          0.1188],\n",
            "        [-0.2280,  0.1687,  0.1105, -0.0461,  0.0576, -0.1748, -0.0102, -0.0898,\n",
            "          0.0230],\n",
            "        [ 0.2180, -0.0400, -0.1665, -0.1573,  0.2129,  0.2154,  0.1257, -0.1344,\n",
            "         -0.0714],\n",
            "        [ 0.1973,  0.2370,  0.1958, -0.1179,  0.1587, -0.1079,  0.0512,  0.0327,\n",
            "          0.0360],\n",
            "        [-0.1095,  0.2247, -0.1316,  0.1270, -0.0708, -0.0436,  0.2231, -0.1866,\n",
            "         -0.2194],\n",
            "        [-0.0696, -0.0646,  0.2353, -0.2224, -0.2026, -0.2035, -0.1488, -0.2150,\n",
            "         -0.0739],\n",
            "        [ 0.1610, -0.2033,  0.0672,  0.2331,  0.1299,  0.2112,  0.2160, -0.0765,\n",
            "          0.1041],\n",
            "        [-0.0548, -0.0373,  0.0424,  0.1529,  0.2104, -0.2201, -0.1288,  0.0107,\n",
            "          0.2486],\n",
            "        [ 0.1153, -0.0140,  0.1817, -0.2092, -0.1880,  0.1320,  0.1317,  0.0537,\n",
            "          0.1840],\n",
            "        [-0.0378, -0.0280, -0.1042, -0.0455, -0.1679, -0.1405,  0.1627,  0.1895,\n",
            "         -0.1372],\n",
            "        [ 0.0146, -0.1941,  0.2432, -0.1474,  0.0891,  0.2482,  0.1518, -0.2395,\n",
            "          0.1549],\n",
            "        [-0.1518,  0.0077,  0.2397, -0.0405, -0.1866,  0.1594,  0.1834,  0.1199,\n",
            "          0.0691],\n",
            "        [ 0.0015,  0.0250,  0.0311, -0.1806,  0.1109,  0.0070,  0.1632, -0.2148,\n",
            "          0.0760],\n",
            "        [ 0.0617,  0.1678, -0.0138, -0.1111,  0.1004, -0.0263, -0.0326, -0.1247,\n",
            "          0.0733],\n",
            "        [ 0.1826,  0.1427, -0.1553,  0.1203,  0.1283,  0.1446,  0.0478, -0.0392,\n",
            "          0.0188],\n",
            "        [-0.0267,  0.1449, -0.1093,  0.0389,  0.1614,  0.1649, -0.1610,  0.1536,\n",
            "         -0.2340],\n",
            "        [-0.2465,  0.2114,  0.1716,  0.0740, -0.1437, -0.0396, -0.0889,  0.2120,\n",
            "          0.0443],\n",
            "        [ 0.1783,  0.1856,  0.0564, -0.1861, -0.1980,  0.1178, -0.2273, -0.1073,\n",
            "         -0.0561],\n",
            "        [-0.0473,  0.0678, -0.0555, -0.1297, -0.1276, -0.1789,  0.1773,  0.2141,\n",
            "         -0.0330],\n",
            "        [ 0.2146,  0.1220, -0.0056,  0.0118,  0.2384,  0.1994, -0.1411, -0.0594,\n",
            "         -0.1721],\n",
            "        [ 0.2165,  0.2149,  0.0443,  0.1005,  0.1279, -0.0805, -0.2085,  0.2058,\n",
            "          0.0737],\n",
            "        [ 0.0608, -0.2133,  0.0305, -0.0238, -0.1123, -0.1719,  0.0761, -0.0998,\n",
            "          0.0745],\n",
            "        [-0.0027,  0.2096, -0.1282, -0.2253,  0.2400,  0.0419,  0.2024,  0.0662,\n",
            "          0.0426],\n",
            "        [ 0.1343,  0.0188,  0.0377,  0.1279, -0.0483,  0.1492,  0.1835, -0.1013,\n",
            "          0.0824],\n",
            "        [-0.1557, -0.0271, -0.1108, -0.0479, -0.0928,  0.0162,  0.2415,  0.1678,\n",
            "          0.0717],\n",
            "        [ 0.2120,  0.0363, -0.1485,  0.1285, -0.1026,  0.0922,  0.0534, -0.1360,\n",
            "         -0.2413],\n",
            "        [-0.1671, -0.0748, -0.1256, -0.0970,  0.0131,  0.1355,  0.0822, -0.1240,\n",
            "         -0.0659],\n",
            "        [-0.2003,  0.1697,  0.2375, -0.2129,  0.1162, -0.0784, -0.0572, -0.2322,\n",
            "          0.1062],\n",
            "        [ 0.1783, -0.0960,  0.0603, -0.2122, -0.1620,  0.1240, -0.1791, -0.0505,\n",
            "         -0.1984],\n",
            "        [ 0.1618, -0.0718,  0.1728,  0.2049,  0.0837, -0.1927, -0.0027, -0.0345,\n",
            "         -0.1097],\n",
            "        [-0.1604,  0.2190,  0.1548, -0.1625, -0.0635,  0.1862,  0.0446, -0.0095,\n",
            "         -0.0956],\n",
            "        [-0.2169,  0.2016,  0.1330,  0.2102, -0.0601, -0.0991, -0.1175, -0.0270,\n",
            "          0.1210],\n",
            "        [-0.0100, -0.1958, -0.1084,  0.1964,  0.0148,  0.0210, -0.0602, -0.1947,\n",
            "          0.0158],\n",
            "        [-0.0431,  0.0246,  0.0477, -0.1846, -0.1082, -0.1304,  0.0890, -0.0844,\n",
            "         -0.0167],\n",
            "        [ 0.1797,  0.0612,  0.1955,  0.1350, -0.2334, -0.2203, -0.1677, -0.1276,\n",
            "         -0.0178],\n",
            "        [-0.0642,  0.0673,  0.0164,  0.0778,  0.2289,  0.2226, -0.0628,  0.1417,\n",
            "          0.0325],\n",
            "        [-0.0209, -0.0981,  0.0111, -0.1236,  0.0106,  0.1573,  0.0265, -0.1883,\n",
            "          0.2369],\n",
            "        [-0.1549, -0.1768, -0.1912, -0.2450, -0.1717, -0.2231, -0.1472,  0.1244,\n",
            "          0.1563],\n",
            "        [-0.0054, -0.2431, -0.0340, -0.0360, -0.2497,  0.0136,  0.2108, -0.2068,\n",
            "          0.1122],\n",
            "        [ 0.1293,  0.1979,  0.0114, -0.2410,  0.0559,  0.0390, -0.1618,  0.1212,\n",
            "          0.2316],\n",
            "        [ 0.0098,  0.1942,  0.1552,  0.1604, -0.1428, -0.1089,  0.2054,  0.2421,\n",
            "         -0.0011],\n",
            "        [ 0.0946, -0.0801,  0.0304, -0.1484, -0.0657,  0.0914, -0.1842,  0.1025,\n",
            "         -0.0212],\n",
            "        [-0.1900, -0.0526,  0.2498, -0.0251, -0.2319, -0.1171,  0.2349, -0.0265,\n",
            "          0.2174],\n",
            "        [-0.0992, -0.1790, -0.1396,  0.0191,  0.2442, -0.1098,  0.0235, -0.0245,\n",
            "          0.0753],\n",
            "        [ 0.0903,  0.1507,  0.1078, -0.1958,  0.1123, -0.1332, -0.1732, -0.1280,\n",
            "         -0.1405],\n",
            "        [ 0.0269,  0.0555, -0.0191,  0.0439, -0.1086,  0.1107, -0.2254, -0.1920,\n",
            "          0.1315],\n",
            "        [-0.1490, -0.1769,  0.1761,  0.1754,  0.0810,  0.1455,  0.1146,  0.1309,\n",
            "         -0.0746],\n",
            "        [ 0.1709, -0.1265, -0.1815,  0.0808,  0.1806,  0.0716, -0.0401,  0.2037,\n",
            "         -0.1478],\n",
            "        [-0.1613, -0.1785, -0.1426, -0.2315, -0.0339,  0.1303,  0.1362, -0.0007,\n",
            "          0.1955],\n",
            "        [-0.2246,  0.0165,  0.2164, -0.0898,  0.0341, -0.1572,  0.0082, -0.0624,\n",
            "          0.1801]], requires_grad=True))\n",
            "weight_ih_l0 has size [64, 9]\n",
            "-------------------------------\n",
            "('weight_hh_l0', Parameter containing:\n",
            "tensor([[ 0.1716, -0.0652,  0.1640,  ..., -0.1503, -0.1717,  0.2027],\n",
            "        [-0.2000, -0.1152,  0.2019,  ..., -0.1459, -0.0459,  0.1293],\n",
            "        [-0.1422,  0.0956,  0.0294,  ..., -0.1336, -0.2429, -0.1866],\n",
            "        ...,\n",
            "        [ 0.0589,  0.0485,  0.0178,  ..., -0.1514, -0.0611, -0.0606],\n",
            "        [ 0.1541, -0.2018, -0.1083,  ...,  0.2233, -0.1222, -0.1334],\n",
            "        [-0.1055,  0.1922, -0.0732,  ..., -0.1016, -0.1487,  0.1422]],\n",
            "       requires_grad=True))\n",
            "weight_hh_l0 has size [64, 16]\n",
            "-------------------------------\n",
            "('bias_ih_l0', Parameter containing:\n",
            "tensor([-0.0267, -0.1721,  0.0974, -0.1947,  0.0459, -0.1512,  0.0632, -0.2378,\n",
            "         0.0748, -0.2288, -0.2351, -0.0036, -0.0402,  0.2253, -0.2460,  0.2485,\n",
            "        -0.0991,  0.1765,  0.0881, -0.0114, -0.1753,  0.0825, -0.1560, -0.0561,\n",
            "         0.0882,  0.2037, -0.2429,  0.2209,  0.0669,  0.0700,  0.0196, -0.0121,\n",
            "         0.1814, -0.1691, -0.1108, -0.2229, -0.1358,  0.0830, -0.0485, -0.0902,\n",
            "        -0.0978,  0.1089, -0.1220,  0.2214,  0.2427,  0.2302,  0.0632,  0.1041,\n",
            "         0.0223,  0.2298,  0.0343, -0.1005, -0.0487,  0.0569, -0.0581,  0.1600,\n",
            "        -0.0884,  0.1846, -0.1524, -0.0283, -0.1175,  0.1749,  0.2316, -0.2193],\n",
            "       requires_grad=True))\n",
            "-------------------------------\n",
            "('bias_hh_l0', Parameter containing:\n",
            "tensor([-0.0054, -0.0646,  0.0664,  0.0746, -0.1961, -0.0671, -0.0718, -0.1108,\n",
            "         0.1849, -0.2070, -0.2394, -0.0871, -0.1844,  0.2353,  0.1664, -0.0148,\n",
            "        -0.0260, -0.1083,  0.0551,  0.1330, -0.0861, -0.1687, -0.1447,  0.1697,\n",
            "         0.1187,  0.1889, -0.0455, -0.1501,  0.1091,  0.0010,  0.1990,  0.0808,\n",
            "        -0.1047,  0.1118,  0.0862,  0.1417, -0.1392, -0.1987, -0.2404, -0.1287,\n",
            "        -0.1312, -0.0147,  0.0161, -0.0799, -0.2480,  0.1496, -0.0149, -0.0445,\n",
            "        -0.1815, -0.1838, -0.1645, -0.0889, -0.2266,  0.0521,  0.0547, -0.0974,\n",
            "        -0.0060,  0.1534,  0.2253,  0.0342,  0.1267, -0.0867, -0.0505,  0.0820],\n",
            "       requires_grad=True))\n",
            "-------------------------------\n",
            "('weight_ih_l1', Parameter containing:\n",
            "tensor([[ 0.1594, -0.0656,  0.0842,  ...,  0.1318,  0.0905, -0.1860],\n",
            "        [ 0.0964,  0.2054,  0.0178,  ...,  0.0334, -0.1711,  0.1059],\n",
            "        [-0.1890,  0.0425,  0.1798,  ..., -0.0472, -0.2083,  0.2154],\n",
            "        ...,\n",
            "        [-0.2339, -0.1306,  0.0733,  ...,  0.2293, -0.1972, -0.0667],\n",
            "        [-0.0520,  0.1968,  0.1639,  ...,  0.2119, -0.1151,  0.1525],\n",
            "        [ 0.2055, -0.1371, -0.0856,  ..., -0.1872, -0.0786, -0.0610]],\n",
            "       requires_grad=True))\n",
            "weight_ih_l1 has size [64, 16]\n",
            "-------------------------------\n",
            "('weight_hh_l1', Parameter containing:\n",
            "tensor([[ 0.1386,  0.1629, -0.0354,  ..., -0.1118, -0.2406, -0.1077],\n",
            "        [-0.0778,  0.1776,  0.1966,  ..., -0.1507,  0.1972, -0.1044],\n",
            "        [-0.0033, -0.2268,  0.0378,  ..., -0.0197, -0.2305, -0.1854],\n",
            "        ...,\n",
            "        [ 0.0106, -0.2111, -0.2293,  ...,  0.0252,  0.2044,  0.2490],\n",
            "        [ 0.1585, -0.0922,  0.1335,  ...,  0.0212,  0.0632, -0.0954],\n",
            "        [-0.1054,  0.1084,  0.2447,  ..., -0.1159, -0.0860, -0.2073]],\n",
            "       requires_grad=True))\n",
            "weight_hh_l1 has size [64, 16]\n",
            "-------------------------------\n",
            "('bias_ih_l1', Parameter containing:\n",
            "tensor([-0.2447, -0.0883, -0.1111, -0.1703, -0.1438, -0.0803,  0.1763, -0.0397,\n",
            "        -0.1308,  0.1406, -0.1200, -0.0969,  0.1449,  0.1998,  0.0977, -0.0640,\n",
            "         0.0878, -0.0221, -0.0479, -0.1142,  0.1178,  0.0656, -0.0473,  0.1716,\n",
            "         0.1908,  0.1128, -0.1174,  0.1015, -0.0135,  0.2488,  0.2480,  0.2175,\n",
            "         0.0094,  0.1888, -0.0517,  0.1012, -0.2100, -0.0269,  0.2098,  0.0420,\n",
            "        -0.1962,  0.0434, -0.0057,  0.0069,  0.1102, -0.1332, -0.1899,  0.0020,\n",
            "        -0.2445, -0.1660, -0.0427, -0.0941, -0.2239,  0.0570, -0.0620, -0.1758,\n",
            "         0.0490,  0.1091,  0.0781,  0.0698, -0.0037, -0.1770, -0.1822,  0.0251],\n",
            "       requires_grad=True))\n",
            "-------------------------------\n",
            "('bias_hh_l1', Parameter containing:\n",
            "tensor([-0.1588,  0.1730, -0.1541,  0.0083,  0.0537,  0.0101, -0.0850,  0.1065,\n",
            "         0.0398, -0.0904, -0.1816, -0.1476,  0.0573,  0.2153, -0.2265, -0.1509,\n",
            "         0.0942,  0.0192,  0.0335, -0.0498, -0.0468,  0.1112, -0.2155, -0.0115,\n",
            "        -0.0491,  0.2059,  0.0679,  0.0491,  0.0863,  0.2046, -0.1956, -0.2003,\n",
            "         0.1272, -0.1456,  0.1228, -0.2104,  0.0317,  0.1990,  0.0386, -0.1107,\n",
            "        -0.1704, -0.1629, -0.0644,  0.0674, -0.2183, -0.2477, -0.0872,  0.0455,\n",
            "         0.1237, -0.1568, -0.0299, -0.0245,  0.2468, -0.1686,  0.1162,  0.1490,\n",
            "         0.0672,  0.1940,  0.0005, -0.0464, -0.1281, -0.0179, -0.1280,  0.1092],\n",
            "       requires_grad=True))\n",
            "-------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👆 64 = 16 x 4\n",
        "\n",
        "16: number of units in the hidden layer\n",
        "\n",
        " 4: number of gates/weights matrices (w_ii, w_if, w_ig, w_io)"
      ],
      "metadata": {
        "id": "x-ytF4J4pC05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a class for the DL model:"
      ],
      "metadata": {
        "id": "Q8_XwND7rGCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMnet(nn.Module):\n",
        "  def __init__(self,input_size,num_hidden,num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    # store parameters\n",
        "    self.input_size = input_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # RNN Layer (LSTM is a type of RNN)\n",
        "    self.lstm = nn.LSTM(input_size,num_hidden,num_layers)\n",
        "\n",
        "    # linear layer for output\n",
        "    self.out = nn.Linear(num_hidden,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    print(f'Input: {list(x.shape)}')\n",
        "\n",
        "    # run through the RNN layer\n",
        "    y,hidden = self.lstm(x)\n",
        "    print(f'RNN-out: {list(y.shape)}')\n",
        "    print(f'RNN-hidden: {list(hidden[0].shape)}')\n",
        "    print(f'RNN-cell: {list(hidden[1].shape)}')\n",
        "\n",
        "    # pass the RNN output through the linear output layer\n",
        "    o = self.out(y)\n",
        "    print(f'Output: {list(o.shape)}')\n",
        "\n",
        "    return o,hidden"
      ],
      "metadata": {
        "id": "HG12AoSkp-J_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of the model and inspect\n",
        "net = LSTMnet(input_size,hidden_size,num_layers)\n",
        "print(net), print(' ')\n",
        "\n",
        "# and check out all learnable parameters\n",
        "for p in net.named_parameters():\n",
        "  print(f'{p[0]:>20} has size {list(p[1].shape)}') # right-aligned within a 20-character wide space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hv-hsgPEkqH",
        "outputId": "128cfeb4-64db-4a67-f324-3ff50196a58e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMnet(\n",
            "  (lstm): LSTM(9, 16, num_layers=2)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n",
            " \n",
            "   lstm.weight_ih_l0 has size [64, 9]\n",
            "   lstm.weight_hh_l0 has size [64, 16]\n",
            "     lstm.bias_ih_l0 has size [64]\n",
            "     lstm.bias_hh_l0 has size [64]\n",
            "   lstm.weight_ih_l1 has size [64, 16]\n",
            "   lstm.weight_hh_l1 has size [64, 16]\n",
            "     lstm.bias_ih_l1 has size [64]\n",
            "     lstm.bias_hh_l1 has size [64]\n",
            "          out.weight has size [1, 16]\n",
            "            out.bias has size [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model with some random data:\n",
        "\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "y = torch.rand(seqlength,batchsize,1)\n",
        "yHat,h = net(X)\n",
        "\n",
        "lossfun = nn.MSELoss()\n",
        "lossfun(yHat,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIrKDbk8EpkQ",
        "outputId": "4e4dfac5-9484-494d-b213-867390e02072"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [5, 2, 9]\n",
            "RNN-out: [5, 2, 16]\n",
            "RNN-hidden: [2, 2, 16]\n",
            "RNN-cell: [2, 2, 16]\n",
            "Output: [5, 2, 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2231, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU:"
      ],
      "metadata": {
        "id": "dkX0aIOKGokK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a GRU instance\n",
        "gru = nn.GRU(input_size,hidden_size,num_layers)\n",
        "gru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZhRqDorGp8c",
        "outputId": "b5e3c28a-b4c8-4c14-d7db-1b00c4503628"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(9, 16, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create some random data & initiate a hidden state\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "# pass data through the model and show the output sizes\n",
        "y,h = gru(X,H) # unlike LSTM, there's no cell states in GRU!\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h.shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-DdQJ3BMmvw",
        "outputId": "4ce803f7-3ab5-4dcb-8aa9-bd65ef34c92b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [2, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the learned parameters and their sizes\n",
        "for p in gru.named_parameters():\n",
        "  # print(p)\n",
        "  print(f'{p[0]:>15} has size {list(p[1].shape)}') # right-aligned within a 15-character wide space\n",
        "  ## 👆if the text is shorter than the specified width (15 characters in this case), it will be padded with spaces on the left to reach the width\n",
        "  # print(\"-------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ1iqZ42OfOT",
        "outputId": "ee53ccf7-a9b5-4817-9d70-112b54f9d704"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   weight_ih_l0 has size [48, 9]\n",
            "   weight_hh_l0 has size [48, 16]\n",
            "     bias_ih_l0 has size [48]\n",
            "     bias_hh_l0 has size [48]\n",
            "   weight_ih_l1 has size [48, 16]\n",
            "   weight_hh_l1 has size [48, 16]\n",
            "     bias_ih_l1 has size [48]\n",
            "     bias_hh_l1 has size [48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👆 48 = 16 x 3\n",
        "\n",
        "16: number of units in the hidden layer\n",
        "\n",
        "3: number of gates/weights matrices (w_ir, w_iz, w_in)"
      ],
      "metadata": {
        "id": "y5ETHwNGPrBk"
      }
    }
  ]
}