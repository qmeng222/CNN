{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/nUtWM0/S4TSs5Qdi8OTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qmeng222/CNN/blob/main/RNN/RNN_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tQOZ-waJOJw2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size  =  9 # number of data channels\n",
        "hidden_size = 16 # number of units in the hidden state\n",
        "num_layers  =  1 # number of vertical stacks of hidden layers\n",
        "actfun      = 'tanh'\n",
        "bias        = True\n",
        "\n",
        "# create an RNN instance\n",
        "rnn = nn.RNN(input_size,hidden_size,num_layers,nonlinearity=actfun,bias=bias) # `num_layers=1, nonlinearity='tanh',bias=True` is default\n",
        "print(rnn) # instance size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIovmWOHU9SW",
        "outputId": "655c0596-f2ac-4ece-a787-8f4941ef3019"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(9, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create some fake data & push it through the RNN instance:"
      ],
      "metadata": {
        "id": "A9SM85w7XkT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create some fake data\n",
        "seqlength = 5\n",
        "batchsize = 2\n",
        "X = torch.rand(seqlength,batchsize,input_size) # torch tensor\n",
        "\n",
        "# create a hidden layer (initialized as zeros)\n",
        "hidden = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "# push data through the model & show the output sizes\n",
        "y,h = rnn(X,hidden) # torch tensors\n",
        "\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h.shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jcxTKCTVw1I",
        "outputId": "17e68af8-5056-498a-f716-193e5a001cf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [1, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scratch/demo:\n",
        "\n",
        "# default hidden state is all zeros if nothing specified:\n",
        "y,h1 = rnn(X,hidden)\n",
        "print(h1, '\\n')\n",
        "\n",
        "y,h2 = rnn(X)\n",
        "print(h2, '\\n')\n",
        "\n",
        "# they're the same! (meaning default=zeros)\n",
        "print(h1-h2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH5ddQmNaOMp",
        "outputId": "d52d017e-3a9f-4b68-f9cd-c54beef23ba6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.2809,  0.2855, -0.1793,  0.3754,  0.0681,  0.4695, -0.0436,\n",
            "           0.3177,  0.8018,  0.1217,  0.1087,  0.1841,  0.3456,  0.0418,\n",
            "           0.0753, -0.1284],\n",
            "         [-0.2278,  0.3388, -0.0153,  0.3632,  0.1878,  0.4778,  0.1053,\n",
            "          -0.0159,  0.7996, -0.0548,  0.0606,  0.0789,  0.3153,  0.3863,\n",
            "           0.2329, -0.2757]]], grad_fn=<StackBackward0>) \n",
            "\n",
            "tensor([[[-0.2809,  0.2855, -0.1793,  0.3754,  0.0681,  0.4695, -0.0436,\n",
            "           0.3177,  0.8018,  0.1217,  0.1087,  0.1841,  0.3456,  0.0418,\n",
            "           0.0753, -0.1284],\n",
            "         [-0.2278,  0.3388, -0.0153,  0.3632,  0.1878,  0.4778,  0.1053,\n",
            "          -0.0159,  0.7996, -0.0548,  0.0606,  0.0789,  0.3153,  0.3863,\n",
            "           0.2329, -0.2757]]], grad_fn=<StackBackward0>) \n",
            "\n",
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
            "       grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the sizes of the weights:\n",
        "for p in rnn.named_parameters():\n",
        "  print(p) # duple\n",
        "  if 'weight' in p[0]:\n",
        "    print(f'{p[0]} has size {list(p[1].shape)}')\n",
        "  print(\"-------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjmASf-ubLGA",
        "outputId": "45b7745c-1782-4e49-8456-1094f3c9683a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight_ih_l0', Parameter containing:\n",
            "tensor([[ 8.7304e-02,  1.5094e-01,  1.5851e-01,  4.6990e-02, -4.7582e-02,\n",
            "         -2.1358e-01, -1.5857e-01, -5.0121e-02,  2.3272e-01],\n",
            "        [-2.0136e-01,  1.6671e-01, -1.8179e-01,  2.0318e-02,  2.0876e-01,\n",
            "          2.5309e-02,  1.4542e-01, -1.6530e-01,  1.4229e-01],\n",
            "        [-1.1852e-01,  8.8165e-02,  1.6479e-01, -4.4847e-02,  1.9075e-01,\n",
            "          1.0064e-01, -1.9595e-01,  8.7732e-02,  1.3616e-02],\n",
            "        [ 1.2927e-01,  1.4370e-01, -7.8339e-02, -8.3005e-02,  1.5582e-01,\n",
            "         -2.1558e-01,  2.3072e-01, -1.7258e-01, -1.1067e-01],\n",
            "        [-1.5122e-01,  2.4495e-01, -9.7879e-03,  3.3051e-05,  1.8997e-01,\n",
            "         -1.0735e-01,  1.1544e-01, -1.5215e-01,  9.5780e-02],\n",
            "        [-6.0916e-02,  1.8608e-01, -8.3411e-02, -7.3063e-02,  2.0731e-01,\n",
            "          1.9774e-01,  2.3049e-01, -2.1326e-01, -8.2132e-02],\n",
            "        [-8.1426e-02, -1.0060e-01, -1.4740e-01,  1.5681e-01,  5.1082e-02,\n",
            "          1.4020e-01, -1.1975e-01, -1.1302e-01,  1.3248e-01],\n",
            "        [-1.6153e-01, -2.1976e-01,  2.3098e-01,  2.1868e-01,  2.0184e-01,\n",
            "         -1.2944e-01,  1.5991e-01, -1.5591e-01, -8.0270e-02],\n",
            "        [ 1.5063e-01,  2.8262e-02,  1.1900e-01,  1.9408e-01,  4.0593e-02,\n",
            "         -1.6742e-02,  6.6965e-02,  1.2632e-01, -1.6453e-01],\n",
            "        [-5.0487e-03, -2.3183e-01,  2.1557e-01,  1.1059e-01,  1.0031e-01,\n",
            "         -1.6969e-01, -1.4723e-01, -8.7853e-02,  1.5356e-01],\n",
            "        [-1.9773e-01,  2.1587e-01, -2.2157e-01, -1.2599e-03,  1.9094e-01,\n",
            "          1.0829e-01,  2.3182e-01, -2.2267e-01, -1.5708e-02],\n",
            "        [ 1.0440e-01, -8.0534e-02, -7.0611e-02,  1.5022e-01,  2.0849e-01,\n",
            "         -1.4587e-01,  8.7415e-02,  8.8707e-02, -1.3567e-01],\n",
            "        [ 1.7725e-01,  1.5112e-01, -1.2662e-01, -1.6797e-01,  1.6034e-01,\n",
            "          1.9445e-01,  2.1538e-01, -1.5222e-01, -9.8034e-02],\n",
            "        [ 2.2499e-01,  1.4405e-01, -2.3674e-01, -6.8883e-02, -3.2687e-02,\n",
            "          1.3086e-01, -1.4570e-01,  1.1569e-01, -1.1857e-02],\n",
            "        [-8.0847e-02,  2.4225e-01, -1.0380e-01, -1.4894e-01,  5.8430e-02,\n",
            "         -1.6859e-01, -4.1866e-02,  6.7303e-02,  4.1174e-02],\n",
            "        [ 1.6394e-01, -1.8604e-01,  6.1155e-02, -7.3824e-02, -1.3020e-01,\n",
            "          1.3486e-01,  5.6283e-02,  2.1312e-01, -9.9985e-02]],\n",
            "       requires_grad=True))\n",
            "weight_ih_l0 has size [16, 9]\n",
            "-------------------------------------\n",
            "('weight_hh_l0', Parameter containing:\n",
            "tensor([[ 0.0892,  0.2162, -0.2085, -0.2301,  0.1325, -0.2217, -0.1827, -0.1289,\n",
            "         -0.1314,  0.2474, -0.2073,  0.1562, -0.0065,  0.1156, -0.1200, -0.0930],\n",
            "        [-0.2051,  0.0295,  0.2480,  0.1846,  0.0519,  0.0012, -0.0409,  0.1301,\n",
            "         -0.0817, -0.0056, -0.0184,  0.2358,  0.1347,  0.1694,  0.0110, -0.0906],\n",
            "        [ 0.0247, -0.1843, -0.0944, -0.0503,  0.1105, -0.0451,  0.2463,  0.1966,\n",
            "         -0.0549,  0.2385,  0.1608, -0.1916, -0.0933, -0.1116, -0.0671, -0.1509],\n",
            "        [ 0.0392, -0.1393,  0.1534,  0.0505,  0.0753,  0.0522,  0.0044, -0.1484,\n",
            "          0.1320, -0.0652, -0.2297, -0.1803,  0.2440,  0.2487, -0.2358, -0.1157],\n",
            "        [-0.0085, -0.2283,  0.0920,  0.2134, -0.1093, -0.0237, -0.1419, -0.1909,\n",
            "          0.2075,  0.1736,  0.2324, -0.0397, -0.0348, -0.1576,  0.2088, -0.0643],\n",
            "        [-0.0681, -0.0200, -0.2307,  0.0365,  0.2108,  0.1400,  0.0164,  0.2273,\n",
            "         -0.0365,  0.0672,  0.2087,  0.1074, -0.1156, -0.0309, -0.1739,  0.0793],\n",
            "        [-0.0293,  0.1740, -0.2221, -0.1298,  0.0859, -0.0772,  0.0732, -0.0983,\n",
            "         -0.1906, -0.2128,  0.1386, -0.2306,  0.0635,  0.0571, -0.2098, -0.2444],\n",
            "        [ 0.2048, -0.1126, -0.0114,  0.1802, -0.0176, -0.1643, -0.2174, -0.1289,\n",
            "          0.0448, -0.0701,  0.2186,  0.1967,  0.2372,  0.0263,  0.0984, -0.1016],\n",
            "        [-0.1979,  0.0233, -0.1342,  0.2115, -0.1031,  0.1615, -0.0235, -0.1045,\n",
            "          0.1514,  0.2215,  0.1337, -0.1714, -0.1673, -0.0506, -0.2020,  0.0442],\n",
            "        [-0.1836, -0.2126, -0.1651,  0.2186, -0.1735, -0.0606,  0.1536,  0.0898,\n",
            "          0.1202, -0.1828, -0.1562, -0.2128,  0.0272, -0.1939, -0.1143,  0.0525],\n",
            "        [-0.0924,  0.0298, -0.1055,  0.0305,  0.0898,  0.0467, -0.1956, -0.2280,\n",
            "         -0.1152,  0.0705, -0.0184,  0.0257, -0.1445,  0.2163,  0.0574, -0.0178],\n",
            "        [-0.2361, -0.2337, -0.2117,  0.1508,  0.1478,  0.0645,  0.0598,  0.2480,\n",
            "          0.0459,  0.1082, -0.0458, -0.1895, -0.1691,  0.0773, -0.2115,  0.1734],\n",
            "        [-0.2175,  0.0842,  0.2127, -0.0909, -0.2367,  0.1432, -0.1497,  0.0416,\n",
            "         -0.1652, -0.0190,  0.0928,  0.0225,  0.1109,  0.2394, -0.0152, -0.2166],\n",
            "        [ 0.0435, -0.2319, -0.2345,  0.0442,  0.2302,  0.1423,  0.1940,  0.0504,\n",
            "          0.0090, -0.2464,  0.1090, -0.1840,  0.2147, -0.1980,  0.1268, -0.1429],\n",
            "        [-0.1598, -0.0829,  0.0659,  0.2472,  0.0404,  0.2299, -0.1796,  0.1201,\n",
            "          0.0236, -0.0741, -0.1474, -0.1091,  0.0706,  0.1549, -0.1130, -0.0694],\n",
            "        [-0.0286,  0.0257,  0.1480,  0.2020, -0.0743, -0.1575, -0.1285,  0.0754,\n",
            "         -0.1073,  0.1027,  0.0614,  0.2322,  0.1093, -0.1266, -0.1214,  0.2220]],\n",
            "       requires_grad=True))\n",
            "weight_hh_l0 has size [16, 16]\n",
            "-------------------------------------\n",
            "('bias_ih_l0', Parameter containing:\n",
            "tensor([-0.0358,  0.0583,  0.0559,  0.2299, -0.0936,  0.1816,  0.0254,  0.1775,\n",
            "         0.1283,  0.0625,  0.0659, -0.0106, -0.1491,  0.0590, -0.0803, -0.1500],\n",
            "       requires_grad=True))\n",
            "-------------------------------------\n",
            "('bias_hh_l0', Parameter containing:\n",
            "tensor([-0.1141,  0.0771, -0.2472,  0.0384, -0.0452,  0.1850,  0.1275, -0.2392,\n",
            "         0.2150, -0.0769,  0.1249, -0.0916,  0.1452, -0.0732,  0.1626, -0.1065],\n",
            "       requires_grad=True))\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a class for the DL model:"
      ],
      "metadata": {
        "id": "iLZavsp2bupo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNnet(nn.Module):\n",
        "  def __init__(self,input_size,num_hidden,num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    # parameters\n",
        "    self.input_size = input_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # RNN Layer\n",
        "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
        "\n",
        "    # linear layer for output\n",
        "    self.out = nn.Linear(num_hidden,1) # num_hidden is the output of the RNN layer\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    print(f'Input: {list(x.shape)}')\n",
        "\n",
        "    # initialize the hidden state\n",
        "    hidden = torch.zeros(self.num_layers,batchsize,self.num_hidden)\n",
        "    print(f'Hidden: {list(hidden.shape)}')\n",
        "\n",
        "    # push through the RNN layer\n",
        "    y,hidden = self.rnn(x,hidden)\n",
        "    print(f'RNN-out: {list(y.shape)}')\n",
        "    print(f'RNN-hidden: {list(hidden.shape)}')\n",
        "\n",
        "    # pass the RNN output through the linear output layer\n",
        "    o = self.out(y)\n",
        "    print(f'Output: {list(o.shape)}')\n",
        "\n",
        "    return o,hidden"
      ],
      "metadata": {
        "id": "fQfifCTlbzQ4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of the model and inspect\n",
        "net = RNNnet(input_size,hidden_size,num_layers)\n",
        "print(net, \"\\n\")\n",
        "\n",
        "# check out sizes of all learnable parameters\n",
        "for p in net.named_parameters():\n",
        "  print(f'{p[0]} has size {list(p[1].shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1KFJPmCb2kA",
        "outputId": "9ce3dc88-a1cc-4321-b78b-e20e7fccfb2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNnet(\n",
            "  (rnn): RNN(9, 16)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            ") \n",
            "\n",
            "rnn.weight_ih_l0 has size [16, 9]\n",
            "rnn.weight_hh_l0 has size [16, 16]\n",
            "rnn.bias_ih_l0 has size [16]\n",
            "rnn.bias_hh_l0 has size [16]\n",
            "out.weight has size [1, 16]\n",
            "out.bias has size [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model with some data:\n",
        "\n",
        "# create some data\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "y = torch.rand(seqlength,batchsize,1)\n",
        "yHat,h = net(X)\n",
        "\n",
        "# try a loss function\n",
        "lossfun = nn.MSELoss()\n",
        "lossfun(yHat,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o87NENxyb33G",
        "outputId": "98013cf8-0e5f-4fb3-c50c-02dc4d45ea06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [5, 2, 9]\n",
            "Hidden: [1, 2, 16]\n",
            "RNN-out: [5, 2, 16]\n",
            "RNN-hidden: [1, 2, 16]\n",
            "Output: [5, 2, 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1055, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}