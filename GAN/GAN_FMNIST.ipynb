{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOcQd4gQYZvrIEE3+p5ZS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qmeng222/CNN/blob/main/GAN/GAN_FMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Tasks:\n",
        "\n",
        " - Utilize a generative adversarial network (GAN) to train a generator that transforms pure random numbers (noise) into FMNIST images.\n",
        " - Keep the full dataset, but only train on 3 image classes\n",
        "    - trouser, sneaker, pullover -> no problem\n",
        "    - trouser, sneaker, sandal (unbalanced classes bias the model towards one class (sneakerâ‰ˆsandal) -> mode collapse\n",
        " - Train 50k batches\n",
        " - Smooth the loss funciton"
      ],
      "metadata": {
        "id": "JG8LfkCH-FMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline as inl\n",
        "inl.backend_inline.set_matplotlib_formats(\"svg\")"
      ],
      "metadata": {
        "id": "d0xeRW-0IU25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Rf-oaIvXR1u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data:"
      ],
      "metadata": {
        "id": "afve4KTfT3vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformations\n",
        "transform = T.Compose([ T.ToTensor(), # [0,255] -> [0,1]\n",
        "                        T.Normalize(.5,.5), # -> [-1,1]\n",
        "                      ])\n",
        "\n",
        "# import the data and simultaneously apply the transform\n",
        "dataset = torchvision.datasets.FashionMNIST(root='./data', download=True, transform=transform)"
      ],
      "metadata": {
        "id": "svhlRxLzT2nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list the categories\n",
        "print(dataset.classes)\n",
        "\n",
        "# pick three categories (leave one line uncommented)\n",
        "# classes2keep = [ 'Trouser','Sneaker','Pullover' ]\n",
        "classes2keep = [ 'Trouser','Sneaker', 'Sandal'  ]\n",
        "\n",
        "# find the corresponding data indices\n",
        "images2use = torch.Tensor()\n",
        "for i in range(len(classes2keep)):\n",
        "  classidx = dataset.classes.index(classes2keep[i])\n",
        "  images2use = torch.cat( (images2use,torch.where(dataset.targets==classidx)[0]), 0).type(torch.long)\n",
        "  print(f'Added class {classes2keep[i]} (index {classidx})')\n",
        "\n",
        "# now select just those images\n",
        "\n",
        "# transform to dataloaders\n",
        "batchsize   = 100\n",
        "sampler     = torch.utils.data.sampler.SubsetRandomSampler(images2use)\n",
        "data_loader = DataLoader(dataset,sampler=sampler,batch_size=batchsize,drop_last=True)"
      ],
      "metadata": {
        "id": "cx9LfLPKUl-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect a few random images\n",
        "\n",
        "X,y = next(iter(data_loader))\n",
        "\n",
        "fig,axs = plt.subplots(3,6,figsize=(10,6))\n",
        "\n",
        "for (i,ax) in enumerate(axs.flatten()):\n",
        "\n",
        "  # extract that image\n",
        "  pic = torch.squeeze(X.data[i])\n",
        "  pic = pic/2 + .5 # undo normalization\n",
        "\n",
        "  # and its label\n",
        "  label = dataset.classes[y[i]]\n",
        "\n",
        "  # and show!\n",
        "  ax.imshow(pic,cmap='gray')\n",
        "  ax.text(14,0,label,ha='center',fontweight='bold',color='k',backgroundcolor='y')\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ni0FsvjYU3B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create classes for the discriminator and generator:"
      ],
      "metadata": {
        "id": "c6QBn8g3U5WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class discriminatorNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(28*28,256)\n",
        "    self.fc2 = nn.Linear(256,256)\n",
        "    self.out = nn.Linear(256,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.leaky_relu( self.fc1(x) )\n",
        "    x = F.leaky_relu( self.fc2(x) )\n",
        "    x = self.out(x)\n",
        "    return torch.sigmoid( x )\n",
        "\n",
        "dnet = discriminatorNet()\n",
        "y = dnet(torch.randn(10,784))\n",
        "y"
      ],
      "metadata": {
        "id": "3OcTt5qCU9fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class generatorNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(64,256)\n",
        "    self.fc2 = nn.Linear(256,256)\n",
        "    self.out = nn.Linear(256,784)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.leaky_relu( self.fc1(x) )\n",
        "    x = F.leaky_relu( self.fc2(x) )\n",
        "    x = self.out(x)\n",
        "    return torch.tanh( x )\n",
        "\n",
        "gnet = generatorNet()\n",
        "y = gnet(torch.randn(10,64))\n",
        "plt.imshow(y[0,:].detach().squeeze().view(28,28));"
      ],
      "metadata": {
        "id": "VKF1mxjjVB7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the models:"
      ],
      "metadata": {
        "id": "eaOKsvSKXGnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "lossfun = nn.BCELoss() # for two possible answers (through Sigmoid return 0 or 1)\n",
        "\n",
        "# create instances of the networks and push to the GPU\n",
        "dnet = discriminatorNet().to(device)\n",
        "gnet = generatorNet().to(device)\n",
        "\n",
        "# two separate optimizers (same algo but different variables)\n",
        "d_optimizer = torch.optim.Adam(dnet.parameters(), lr=.0003)\n",
        "g_optimizer = torch.optim.Adam(gnet.parameters(), lr=.0003)"
      ],
      "metadata": {
        "id": "QG3ugzMJXJFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell takes ~13 mins with 50k batches\n",
        "num_epochs = int(50000/len(data_loader))\n",
        "\n",
        "losses = np.zeros((num_epochs*len(data_loader),2))\n",
        "lossi  = 0\n",
        "\n",
        "for epochi in range(num_epochs):\n",
        "\n",
        "  for data,_ in data_loader:\n",
        "\n",
        "    # send data to GPU\n",
        "    data = data.view(batchsize,-1).to(device)\n",
        "\n",
        "\n",
        "    # labels used for real and fake images\n",
        "    real_labels = torch.ones(batchsize,1).to(device)\n",
        "    fake_labels = torch.zeros(batchsize,1).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    ### ---------------- Train the discriminator ---------------- ###\n",
        "\n",
        "    # forward pass and loss for REAL pictures\n",
        "    pred_real   = dnet(data)                     # output of discriminator\n",
        "    d_loss_real = lossfun(pred_real,real_labels) # all labels are 1\n",
        "\n",
        "    # forward pass and loss for FAKE pictures\n",
        "    fake_images = gnet( torch.randn(batchsize,64).to(device) ) # output of generator\n",
        "    pred_fake   = dnet(fake_images)                            # pass through discriminator\n",
        "    d_loss_fake = lossfun(pred_fake,fake_labels)               # all labels are 0\n",
        "\n",
        "    # collect loss (using combined losses)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    losses[lossi,0] = d_loss.item()\n",
        "\n",
        "    # backprop\n",
        "    d_optimizer.zero_grad()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    ### ---------------- Train the generator ---------------- ###\n",
        "\n",
        "    # create fake images and compute loss\n",
        "    fake_images = gnet( torch.randn(batchsize,64).to(device) )\n",
        "    pred_fake   = dnet(fake_images)\n",
        "\n",
        "    # compute and collect loss\n",
        "    g_loss = lossfun(pred_fake,real_labels)\n",
        "    losses[lossi,1] = g_loss.item()\n",
        "\n",
        "    # backprop\n",
        "    g_optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    # increment loss counter\n",
        "    lossi += 1\n",
        "\n",
        "\n",
        "  # print out a status message\n",
        "  msg = f'Finished epoch {epochi+1}/{num_epochs}'\n",
        "  sys.stdout.write('\\r' + msg)"
      ],
      "metadata": {
        "id": "r4HN_xZed1Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a 1D smoothing filter\n",
        "def smooth(x,k=15):\n",
        "  return np.convolve(x,np.ones(k)/k,mode='same')"
      ],
      "metadata": {
        "id": "7WHL1hYvd4DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
        "\n",
        "ax[0].plot(smooth(losses[:,0]))\n",
        "ax[0].plot(smooth(losses[:,1]))\n",
        "ax[0].set_xlabel('Batches')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Model loss')\n",
        "ax[0].legend(['Discrimator','Generator'])\n",
        "# ax[0].set_xlim([4000,6000])\n",
        "\n",
        "ax[1].plot(losses[::5,0],losses[::5,1],'k.',alpha=.1)\n",
        "ax[1].set_xlabel('Discriminator loss')\n",
        "ax[1].set_ylabel('Generator loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YgfmTGFCd8sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's see some fake FMNIST images:"
      ],
      "metadata": {
        "id": "5RcZUirDd-3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the images from the generator network\n",
        "gnet.eval()\n",
        "fake_data = gnet(torch.randn(18,64).to(device)).cpu()\n",
        "\n",
        "# and visualize...\n",
        "fig,axs = plt.subplots(3,6,figsize=(12,6))\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "  ax.imshow(fake_data[i,:,].detach().view(28,28),cmap='gray')\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.suptitle(classes2keep,y=.95,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DIzYW6Z4eEwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}